{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(data.data, columns = data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_target = pd.DataFrame(data.target, columns =['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.concat([iris, iris_target], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test data \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test\\\n",
    "= train_test_split(iris.iloc[:,:-1],iris.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leakage -> \n",
    "# 데이터가 작으면 정규 분포를 안띨 확률이 많다. \n",
    "# 작은데 데이터를 또 쪼개기 때문에 안좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "96                 5.7               2.9                4.2               1.3\n",
       "33                 5.5               4.2                1.4               0.2\n",
       "106                4.9               2.5                4.5               1.7\n",
       "142                5.8               2.7                5.1               1.9\n",
       "118                7.7               2.6                6.9               2.3\n",
       "7                  5.0               3.4                1.5               0.2\n",
       "140                6.7               3.1                5.6               2.4\n",
       "73                 6.1               2.8                4.7               1.2\n",
       "46                 5.1               3.8                1.6               0.2\n",
       "54                 6.5               2.8                4.6               1.5\n",
       "30                 4.8               3.1                1.6               0.2\n",
       "114                5.8               2.8                5.1               2.4\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "103                6.3               2.9                5.6               1.8\n",
       "35                 5.0               3.2                1.2               0.2\n",
       "138                6.0               3.0                4.8               1.8\n",
       "91                 6.1               3.0                4.6               1.4\n",
       "112                6.8               3.0                5.5               2.1\n",
       "16                 5.4               3.9                1.3               0.4\n",
       "94                 5.6               2.7                4.2               1.3\n",
       "42                 4.4               3.2                1.3               0.2\n",
       "126                6.2               2.8                4.8               1.8\n",
       "99                 5.7               2.8                4.1               1.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "119                6.0               2.2                5.0               1.5\n",
       "67                 5.8               2.7                4.1               1.0\n",
       "136                6.3               3.4                5.6               2.4\n",
       "124                6.7               3.3                5.7               2.1\n",
       "74                 6.4               2.9                4.3               1.3\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "70                 5.9               3.2                4.8               1.8\n",
       "101                5.8               2.7                5.1               1.9\n",
       "88                 5.6               3.0                4.1               1.3\n",
       "21                 5.1               3.7                1.5               0.4\n",
       "130                7.4               2.8                6.1               1.9\n",
       "41                 4.5               2.3                1.3               0.3\n",
       "105                7.6               3.0                6.6               2.1\n",
       "133                6.3               2.8                5.1               1.5\n",
       "14                 5.8               4.0                1.2               0.2\n",
       "38                 4.4               3.0                1.3               0.2\n",
       "141                6.9               3.1                5.1               2.3\n",
       "83                 6.0               2.7                5.1               1.6\n",
       "81                 5.5               2.4                3.7               1.0\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "80                 5.5               2.4                3.8               1.1\n",
       "131                7.9               3.8                6.4               2.0\n",
       "10                 5.4               3.7                1.5               0.2\n",
       "149                5.9               3.0                5.1               1.8\n",
       "65                 6.7               3.1                4.4               1.4\n",
       "147                6.5               3.0                5.2               2.0\n",
       "61                 5.9               3.0                4.2               1.5\n",
       "51                 6.4               3.2                4.5               1.5\n",
       "13                 4.3               3.0                1.1               0.1\n",
       "77                 6.7               3.0                5.0               1.7\n",
       "143                6.8               3.2                5.9               2.3\n",
       "123                6.3               2.7                4.9               1.8\n",
       "120                6.9               3.2                5.7               2.3\n",
       "92                 5.8               2.6                4.0               1.2\n",
       "134                6.1               2.6                5.6               1.4\n",
       "145                6.7               3.0                5.2               2.3\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pandas에서도 할 수 있다.\n",
    "train = iris.sample(frac = 0.75) # 75% 랜덤하게 뽑는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pop() missing 1 required positional argument: 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-546f581da765>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# dictionary에서 중요한 개념\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# mutable -> 자기자신도 바뀌고 리턴값도 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: pop() missing 1 required positional argument: 'item'"
     ]
    }
   ],
   "source": [
    "train.pop()\n",
    "# dictionary에서 중요한 개념 \n",
    "# mutable -> 자기자신도 바뀌고 리턴값도 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass DataFrame with boolean values only",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b15c1dac75de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \"\"\"\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2912\u001b[0m         \u001b[1;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_frame\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3007\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3008\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3009\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must pass DataFrame with boolean values only'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3010\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass DataFrame with boolean values only"
     ]
    }
   ],
   "source": [
    "iris.pop(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn= KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0,\n",
       "       1, 0, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129    2\n",
       "89     1\n",
       "78     1\n",
       "17     0\n",
       "57     1\n",
       "45     0\n",
       "49     0\n",
       "39     0\n",
       "117    2\n",
       "110    2\n",
       "6      0\n",
       "104    2\n",
       "9      0\n",
       "47     0\n",
       "48     0\n",
       "37     0\n",
       "40     0\n",
       "43     0\n",
       "115    2\n",
       "137    2\n",
       "148    2\n",
       "18     0\n",
       "79     1\n",
       "34     0\n",
       "63     1\n",
       "25     0\n",
       "72     1\n",
       "125    2\n",
       "26     0\n",
       "59     1\n",
       "102    2\n",
       "87     1\n",
       "19     0\n",
       "107    2\n",
       "95     1\n",
       "64     1\n",
       "12     0\n",
       "127    2\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0,\n",
       "       1, 0, 1, 0, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이로 바꿔준다. \n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(knn.predict(x_test) == y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test, y_test) # 위에 계싼한 것과 밑에 계산한 것이 같은 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "# scikit에서는 warning을 많이 해준다. -> 다음 버전에는 뭐가 바꿨다라는 것을 알려주는 것  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 어느 정도 필요할까 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱, 선형 회귀의 결과 값이 비슷하면 성형성을 띄는 것 (?)\n",
    "# 비션형이 훨 씬 더 좋으면 비선형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대부분 선형 알고리즘 안 좋아하고 성능을 높이는 것을 좋아함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비선형 알고리즘 중에서 nueral network은 데이터가 많으면 많을 수 록 좋은 알고리즘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic 으로 먼저 분석하는 이유는 선형인지 아닌지를 확인하기 위해서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree는 설명가능하다. \n",
    "# if then으로 성능을 다 만들 수 있다. \n",
    "# 지니? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification and regression trees - leo breiman two cultures\n",
    "\n",
    "# 의사결정나무 -> 앙상블 -> RandomForest \n",
    "# 앙상블 : 오버피팅이 잘 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스턴스화 \n",
    "# scikit에서 tree모델은 옵션도 별로없고 별로임\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.decision_path(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.decision_path(x_test)\n",
    "# sparse matrix 연결안됐을 때 성능을 보면된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 알고리즘이 어떤 상황에 잘되는가?\n",
    "\n",
    "\n",
    "# boosting 계열 \n",
    "# https://scikit-learn.org/stable/tutorial/machine_learning_map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석의 80%는 전처리하는데 쓰인다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석하는 사람이 데이터를 수집하는게 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07237001, 0.02034993, 0.47786808, 0.42941198])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_\n",
    "# 노드의 중요성을 알려주는 애"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "# scikit 에서는 잘 안쓴다.\n",
    "# 파이썬에서 쓰는게 더 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 3가지 알고리즘 - 가우시안 알고리즘 \n",
    "\n",
    "# XGBoosting \n",
    "# Neural nextwork는 나중에 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "# 성능 높이는데 도움을 준다. \n",
    "# 사람처럼 행동하는 것이 있다. (전략이 있다.)\n",
    "\n",
    "# 뭐하면 오직 전처리(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyer parameter -> 최적으로 만든느 것을 노가다이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.9642857142857143\n",
      "3 0.9642857142857143\n",
      "4 0.9732142857142857\n",
      "5 0.9821428571428571\n",
      "6 0.9821428571428571\n",
      "7 0.9732142857142857\n",
      "8 0.9732142857142857\n",
      "9 0.9821428571428571\n",
      "10 0.9821428571428571\n",
      "11 0.9732142857142857\n",
      "12 0.9821428571428571\n",
      "13 0.9732142857142857\n",
      "14 0.9821428571428571\n",
      "15 0.9821428571428571\n",
      "16 0.9821428571428571\n",
      "17 0.9732142857142857\n",
      "18 0.9821428571428571\n",
      "19 0.9732142857142857\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    print(i, knn.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고수들은 for 안쓰고 grid \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 작을 때 쓴는 애가 cross validation\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plot_cross_validation.plot_cross_validation()\n",
    "# crossvalidation -> 성능 평가 (비교 용도) \n",
    "# & 모델의 어느정도 정합성 - (overfitting) 확인용도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection 관점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# 정확도 알려주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn알고리즘을 인스턴스화한 것 \n",
    "cross_val_score(KNeighborsClassifier(), iris.iloc[:,:-1], iris.iloc[:,-1], cv=10, n_jobs=-1).mean()\n",
    "\n",
    "# 이모델 평균 \n",
    "# 데이터가 작을 때는 크로스 밸리데이션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다 수학이다. \n",
    "# 깔끔하고 아름답지만 성능이 좀 느리다. \n",
    "# 차웑증가 시켜서 (?)\n",
    "# 극좌표계를 통해 직선으로 만들어서 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.mean(cross_val_score(KNeighborsClassifier(), iris.iloc[:,:-1], iris.iloc[:,-1], cv=10, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.mean(cross_val_score(SVC(), iris.iloc[:,:-1], iris.iloc[:,-1], cv=10, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Grid -> crossvalidation을 사용한다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors':[1,2,3,4,5,6,7,8,9], \"leaf_size\":range(10,51)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
    "# 내부적으로 계산하는 수선을 정해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'leaf_size': range(10, 51)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(iris.iloc[:,:-1], iris.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 10, 'n_neighbors': 5}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ \n",
    "# 최적의 파라미터의 값을 구해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Cho Gyung Ah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00333071</td>\n",
       "      <td>0.00333301</td>\n",
       "      <td>0.00166583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00653998</td>\n",
       "      <td>0.00266671</td>\n",
       "      <td>0.000666142</td>\n",
       "      <td>0.00520817</td>\n",
       "      <td>0.00520802</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000471876</td>\n",
       "      <td>0.00124747</td>\n",
       "      <td>0.00124662</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00662564</td>\n",
       "      <td>0.000472045</td>\n",
       "      <td>0.000942066</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0.00736525</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00566451</td>\n",
       "      <td>0.00499503</td>\n",
       "      <td>0.00301329</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00687385</td>\n",
       "      <td>0.00499479</td>\n",
       "      <td>0.00169881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0104164</td>\n",
       "      <td>0.00520802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00520817</td>\n",
       "      <td>0.00520817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0104163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00520825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000470641</td>\n",
       "      <td>0.00141467</td>\n",
       "      <td>0.00217326</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00651502</td>\n",
       "      <td>1.10693e-06</td>\n",
       "      <td>0.00240248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736553</td>\n",
       "      <td>0.00736525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00736558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_leaf_size</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 1}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 2}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 3}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 4}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 5}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 6}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 7}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 8}</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 9}</td>\n",
       "      <td>{'leaf_size': 11, 'n_neighbors': 1}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'leaf_size': 49, 'n_neighbors': 9}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 1}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 2}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 3}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 4}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 5}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 6}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 7}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 8}</td>\n",
       "      <td>{'leaf_size': 50, 'n_neighbors': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0333333</td>\n",
       "      <td>0.00878204</td>\n",
       "      <td>0.0159247</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.00914659</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.000571662</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.0333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.0333333</td>\n",
       "      <td>0.00878204</td>\n",
       "      <td>0.0159247</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.00914659</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.00902067</td>\n",
       "      <td>0.000571662</td>\n",
       "      <td>0.00902067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>288</td>\n",
       "      <td>329</td>\n",
       "      <td>42</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>42</td>\n",
       "      <td>124</td>\n",
       "      <td>288</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>288</td>\n",
       "      <td>329</td>\n",
       "      <td>42</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>42</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.959596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.95098</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.95098</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.976728</td>\n",
       "      <td>0.963458</td>\n",
       "      <td>0.963359</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>0.973361</td>\n",
       "      <td>0.970093</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976728</td>\n",
       "      <td>0.963458</td>\n",
       "      <td>0.963359</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>0.966726</td>\n",
       "      <td>0.973361</td>\n",
       "      <td>0.970093</td>\n",
       "      <td>0.966726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00932036</td>\n",
       "      <td>0.0187064</td>\n",
       "      <td>0.0125044</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0.0125256</td>\n",
       "      <td>0.00776735</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00932036</td>\n",
       "      <td>0.0187064</td>\n",
       "      <td>0.0125044</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0.00925595</td>\n",
       "      <td>0.0125256</td>\n",
       "      <td>0.00776735</td>\n",
       "      <td>0.00925595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    \\\n",
       "mean_fit_time                                0.00333071   \n",
       "std_fit_time                                0.000471876   \n",
       "mean_score_time                              0.00566451   \n",
       "std_score_time                              0.000470641   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     1   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 1}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.921569   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                0.966667   \n",
       "std_test_score                                0.0333333   \n",
       "rank_test_score                                     288   \n",
       "split0_train_score                                    1   \n",
       "split1_train_score                                    1   \n",
       "split2_train_score                                    1   \n",
       "mean_train_score                                      1   \n",
       "std_train_score                                       0   \n",
       "\n",
       "                                                    1    \\\n",
       "mean_fit_time                                0.00333301   \n",
       "std_fit_time                                 0.00124747   \n",
       "mean_score_time                              0.00499503   \n",
       "std_score_time                               0.00141467   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     2   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 2}   \n",
       "split0_test_score                              0.960784   \n",
       "split1_test_score                              0.941176   \n",
       "split2_test_score                              0.958333   \n",
       "mean_test_score                                0.953333   \n",
       "std_test_score                               0.00878204   \n",
       "rank_test_score                                     329   \n",
       "split0_train_score                             0.969697   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                             0.970588   \n",
       "mean_train_score                               0.976728   \n",
       "std_train_score                              0.00932036   \n",
       "\n",
       "                                                    2    \\\n",
       "mean_fit_time                                0.00166583   \n",
       "std_fit_time                                 0.00124662   \n",
       "mean_score_time                              0.00301329   \n",
       "std_score_time                               0.00217326   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     3   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 3}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                    0.98   \n",
       "std_test_score                                0.0159247   \n",
       "rank_test_score                                      42   \n",
       "split0_train_score                             0.949495   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                              0.95098   \n",
       "mean_train_score                               0.963458   \n",
       "std_train_score                               0.0187064   \n",
       "\n",
       "                                                    3    \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     4   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 4}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.949495   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.963359   \n",
       "std_train_score                               0.0125044   \n",
       "\n",
       "                                                    4    \\\n",
       "mean_fit_time                                0.00653998   \n",
       "std_fit_time                                 0.00662564   \n",
       "mean_score_time                              0.00687385   \n",
       "std_score_time                               0.00651502   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     5   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 5}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                0.986667   \n",
       "std_test_score                               0.00914659   \n",
       "rank_test_score                                       1   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    5    \\\n",
       "mean_fit_time                                0.00266671   \n",
       "std_fit_time                                0.000472045   \n",
       "mean_score_time                              0.00499479   \n",
       "std_score_time                              1.10693e-06   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     6   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 6}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    6    \\\n",
       "mean_fit_time                               0.000666142   \n",
       "std_fit_time                                0.000942066   \n",
       "mean_score_time                              0.00169881   \n",
       "std_score_time                               0.00240248   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     7   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 7}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                             0.970588   \n",
       "mean_train_score                               0.973361   \n",
       "std_train_score                               0.0125256   \n",
       "\n",
       "                                                    7    \\\n",
       "mean_fit_time                                0.00520817   \n",
       "std_fit_time                                 0.00736547   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     8   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 8}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                    0.98   \n",
       "std_test_score                              0.000571662   \n",
       "rank_test_score                                      42   \n",
       "split0_train_score                             0.969697   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.970093   \n",
       "std_train_score                              0.00776735   \n",
       "\n",
       "                                                    8    \\\n",
       "mean_fit_time                                0.00520802   \n",
       "std_fit_time                                 0.00736525   \n",
       "mean_score_time                               0.0104164   \n",
       "std_score_time                               0.00736553   \n",
       "param_leaf_size                                      10   \n",
       "param_n_neighbors                                     9   \n",
       "params              {'leaf_size': 10, 'n_neighbors': 9}   \n",
       "split0_test_score                              0.960784   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    9    ...  \\\n",
       "mean_fit_time                                         0  ...   \n",
       "std_fit_time                                          0  ...   \n",
       "mean_score_time                              0.00520802  ...   \n",
       "std_score_time                               0.00736525  ...   \n",
       "param_leaf_size                                      11  ...   \n",
       "param_n_neighbors                                     1  ...   \n",
       "params              {'leaf_size': 11, 'n_neighbors': 1}  ...   \n",
       "split0_test_score                              0.980392  ...   \n",
       "split1_test_score                              0.921569  ...   \n",
       "split2_test_score                                     1  ...   \n",
       "mean_test_score                                0.966667  ...   \n",
       "std_test_score                                0.0333333  ...   \n",
       "rank_test_score                                     288  ...   \n",
       "split0_train_score                                    1  ...   \n",
       "split1_train_score                                    1  ...   \n",
       "split2_train_score                                    1  ...   \n",
       "mean_train_score                                      1  ...   \n",
       "std_train_score                                       0  ...   \n",
       "\n",
       "                                                    359  \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                              0.00520817   \n",
       "std_score_time                               0.00736547   \n",
       "param_leaf_size                                      49   \n",
       "param_n_neighbors                                     9   \n",
       "params              {'leaf_size': 49, 'n_neighbors': 9}   \n",
       "split0_test_score                              0.960784   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    360  \\\n",
       "mean_fit_time                                0.00520817   \n",
       "std_fit_time                                 0.00736547   \n",
       "mean_score_time                              0.00520817   \n",
       "std_score_time                               0.00736547   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     1   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 1}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.921569   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                0.966667   \n",
       "std_test_score                                0.0333333   \n",
       "rank_test_score                                     288   \n",
       "split0_train_score                                    1   \n",
       "split1_train_score                                    1   \n",
       "split2_train_score                                    1   \n",
       "mean_train_score                                      1   \n",
       "std_train_score                                       0   \n",
       "\n",
       "                                                    361  \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     2   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 2}   \n",
       "split0_test_score                              0.960784   \n",
       "split1_test_score                              0.941176   \n",
       "split2_test_score                              0.958333   \n",
       "mean_test_score                                0.953333   \n",
       "std_test_score                               0.00878204   \n",
       "rank_test_score                                     329   \n",
       "split0_train_score                             0.969697   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                             0.970588   \n",
       "mean_train_score                               0.976728   \n",
       "std_train_score                              0.00932036   \n",
       "\n",
       "                                                    362  \\\n",
       "mean_fit_time                                0.00520817   \n",
       "std_fit_time                                 0.00736547   \n",
       "mean_score_time                              0.00520841   \n",
       "std_score_time                               0.00736581   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     3   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 3}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                    0.98   \n",
       "std_test_score                                0.0159247   \n",
       "rank_test_score                                      42   \n",
       "split0_train_score                             0.949495   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                              0.95098   \n",
       "mean_train_score                               0.963458   \n",
       "std_train_score                               0.0187064   \n",
       "\n",
       "                                                    363  \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     4   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 4}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.949495   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.963359   \n",
       "std_train_score                               0.0125044   \n",
       "\n",
       "                                                    364  \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                               0.0104163   \n",
       "std_score_time                               0.00736547   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     5   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 5}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                                     1   \n",
       "mean_test_score                                0.986667   \n",
       "std_test_score                               0.00914659   \n",
       "rank_test_score                                       1   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    365  \\\n",
       "mean_fit_time                                0.00520802   \n",
       "std_fit_time                                 0.00736525   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     6   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 6}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.966726   \n",
       "std_train_score                              0.00925595   \n",
       "\n",
       "                                                    366  \\\n",
       "mean_fit_time                                         0   \n",
       "std_fit_time                                          0   \n",
       "mean_score_time                              0.00520841   \n",
       "std_score_time                               0.00736581   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     7   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 7}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.960784   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                0.973333   \n",
       "std_test_score                               0.00902067   \n",
       "rank_test_score                                     124   \n",
       "split0_train_score                             0.959596   \n",
       "split1_train_score                             0.989899   \n",
       "split2_train_score                             0.970588   \n",
       "mean_train_score                               0.973361   \n",
       "std_train_score                               0.0125256   \n",
       "\n",
       "                                                    367  \\\n",
       "mean_fit_time                                0.00520857   \n",
       "std_fit_time                                 0.00736603   \n",
       "mean_score_time                                       0   \n",
       "std_score_time                                        0   \n",
       "param_leaf_size                                      50   \n",
       "param_n_neighbors                                     8   \n",
       "params              {'leaf_size': 50, 'n_neighbors': 8}   \n",
       "split0_test_score                              0.980392   \n",
       "split1_test_score                              0.980392   \n",
       "split2_test_score                              0.979167   \n",
       "mean_test_score                                    0.98   \n",
       "std_test_score                              0.000571662   \n",
       "rank_test_score                                      42   \n",
       "split0_train_score                             0.969697   \n",
       "split1_train_score                             0.979798   \n",
       "split2_train_score                             0.960784   \n",
       "mean_train_score                               0.970093   \n",
       "std_train_score                              0.00776735   \n",
       "\n",
       "                                                    368  \n",
       "mean_fit_time                                         0  \n",
       "std_fit_time                                          0  \n",
       "mean_score_time                              0.00520825  \n",
       "std_score_time                               0.00736558  \n",
       "param_leaf_size                                      50  \n",
       "param_n_neighbors                                     9  \n",
       "params              {'leaf_size': 50, 'n_neighbors': 9}  \n",
       "split0_test_score                              0.960784  \n",
       "split1_test_score                              0.980392  \n",
       "split2_test_score                              0.979167  \n",
       "mean_test_score                                0.973333  \n",
       "std_test_score                               0.00902067  \n",
       "rank_test_score                                     124  \n",
       "split0_train_score                             0.959596  \n",
       "split1_train_score                             0.979798  \n",
       "split2_train_score                             0.960784  \n",
       "mean_train_score                               0.966726  \n",
       "std_train_score                              0.00925595  \n",
       "\n",
       "[18 rows x 369 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search -> 성능이 안좋을 확률이 꽤 있다.\n",
    "\n",
    "# 문자는 숫자로 바꿔야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "120    1\n",
       "121    1\n",
       "122    1\n",
       "123    1\n",
       "124    1\n",
       "125    1\n",
       "126    1\n",
       "127    1\n",
       "128    1\n",
       "129    1\n",
       "130    1\n",
       "131    1\n",
       "132    1\n",
       "133    1\n",
       "134    1\n",
       "135    1\n",
       "136    1\n",
       "137    1\n",
       "138    1\n",
       "139    1\n",
       "140    1\n",
       "141    1\n",
       "142    1\n",
       "143    1\n",
       "144    1\n",
       "145    1\n",
       "146    1\n",
       "147    1\n",
       "148    1\n",
       "149    1\n",
       "Name: species, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 인코딩 ( 문자를 숫자로 )\n",
    "iris.species.map({'setosa':0,'virginica': 1,'versicolor':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 때 x에 쓰려면 조심해야한다. ? 라벨링?\n",
    "# 라벨링 조심해야한다. -> 임베딩 방식 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit_transform(iris.species)\n",
    "# predict or transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot 인코딩 -> 더미 변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "0         1           0          0\n",
       "1         1           0          0\n",
       "2         1           0          0\n",
       "3         1           0          0\n",
       "4         1           0          0\n",
       "5         1           0          0\n",
       "6         1           0          0\n",
       "7         1           0          0\n",
       "8         1           0          0\n",
       "9         1           0          0\n",
       "10        1           0          0\n",
       "11        1           0          0\n",
       "12        1           0          0\n",
       "13        1           0          0\n",
       "14        1           0          0\n",
       "15        1           0          0\n",
       "16        1           0          0\n",
       "17        1           0          0\n",
       "18        1           0          0\n",
       "19        1           0          0\n",
       "20        1           0          0\n",
       "21        1           0          0\n",
       "22        1           0          0\n",
       "23        1           0          0\n",
       "24        1           0          0\n",
       "25        1           0          0\n",
       "26        1           0          0\n",
       "27        1           0          0\n",
       "28        1           0          0\n",
       "29        1           0          0\n",
       "..      ...         ...        ...\n",
       "120       0           0          1\n",
       "121       0           0          1\n",
       "122       0           0          1\n",
       "123       0           0          1\n",
       "124       0           0          1\n",
       "125       0           0          1\n",
       "126       0           0          1\n",
       "127       0           0          1\n",
       "128       0           0          1\n",
       "129       0           0          1\n",
       "130       0           0          1\n",
       "131       0           0          1\n",
       "132       0           0          1\n",
       "133       0           0          1\n",
       "134       0           0          1\n",
       "135       0           0          1\n",
       "136       0           0          1\n",
       "137       0           0          1\n",
       "138       0           0          1\n",
       "139       0           0          1\n",
       "140       0           0          1\n",
       "141       0           0          1\n",
       "142       0           0          1\n",
       "143       0           0          1\n",
       "144       0           0          1\n",
       "145       0           0          1\n",
       "146       0           0          1\n",
       "147       0           0          1\n",
       "148       0           0          1\n",
       "149       0           0          1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더미변수 만드는 것 \n",
    "pd.get_dummies(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit에서도 더미 변수 만드는 방법이 있다.\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit_transform(iris[['species']]).toarray()\n",
    "# species -> 1차원 -> fancy 인코딩\n",
    "\n",
    "# transform?\n",
    "# toarray() ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['setosa']], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.inverse_transform([[1.,0.,0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica'], dtype=object)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미변수 \n",
    "# 크기 문제가 없다. -> 하지만 차원의 저주가 있을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
